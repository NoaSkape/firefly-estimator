---
description: How to use OpenAI's Responses API accurately in this codebase
---

### Overview
Use the OpenAI Responses API to power agentic workflows with stateful, multi-step interactions and built-in tools (web search, file search, computer use). It unifies the simplicity of Chat Completions with tool-use from the Assistants API and is the recommended path going forward.

- Stateful interactions supported (multi-turn without manual state management)
- Built-in tools: web search, file search, computer use
- Background mode for long/complex reasoning tasks
- Reasoning summaries for debugging/auditing
- Assistants API is being deprecated; migrate to Responses API

### Prerequisites
- Set `OPENAI_API_KEY` in your environment (e.g., `.env`, Vercel project settings)
- Use Node 18+ (Node 22.x in this project)

### Minimal single-turn request
Basic call using `fetch` with a single user input.
```javascript
import 'dotenv/config';

const response = await fetch('https://api.openai.com/v1/responses', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'gpt-4.1',
    input: [
      { role: 'user', content: 'Summarize the key features of the Responses API.' }
    ]
  })
});

if (!response.ok) throw new Error(`OpenAI error ${response.status}`);
const data = await response.json();
console.log(data);
```

### Streaming responses (recommended for UX)
Enable streaming for faster token-by-token UI updates.
```javascript
const response = await fetch('https://api.openai.com/v1/responses', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'gpt-4.1',
    input: [{ role: 'user', content: 'List three benefits of background mode.' }],
    stream: true
  })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();
while (true) {
  const { value, done } = await reader.read();
  if (done) break;
  const chunk = decoder.decode(value, { stream: true });
  // Parse event stream chunks per the Responses API streaming format
  // and append to your UI incrementally
}
```

### Using built-in tools
Request tool use by including the `tools` array; the model will call tools as needed. Handle tool calls and then send results back as follow-ups.
```javascript
const res = await fetch('https://api.openai.com/v1/responses', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'gpt-4.1',
    input: [{ role: 'user', content: 'Find today\'s headline on space exploration and summarize it.' }],
    tools: [
      { type: 'web_search' }
    ],
    tool_choice: 'auto'
  })
});
const data = await res.json();

// If the model requests a tool call, execute it, then provide a follow-up input
// with the tool result to let the model continue. Repeat until final answer.
```

### Managing conversation state
- For multi-turn chats, keep prior turns in `input` or use the API's stateful conversation support.
- Maintain a `conversationId` in your app logic and include it per Responses API guidance to persist context across turns.

### Background mode for long tasks
- For long-running tasks (e.g., multi-step research), use the API’s background execution mode to avoid timeouts.
- Poll for completion or use callbacks/webhooks as supported by your runtime.

### Error handling and observability
- The API returns consistent, detailed error payloads; log `status`, `type`, and `message`.
- Consider enabling reasoning summaries for easier debugging during development.

### Migration tips (Assistants → Responses)
- Replace `messages`/`tools` usage from Assistants with the Responses API equivalents.
- Built-in tools (web search, file search, computer use) can replace custom tool wiring in many cases.
- Consolidate to a single Responses call loop that:
  1) Sends user/app input and available tools
  2) Detects tool calls and executes them
  3) Feeds tool results back as a follow-up
  4) Streams final output to the UI

### Security
- Never log `OPENAI_API_KEY`.
- Validate/limit tool inputs and outputs (especially computer/file use).
- Use rate limiting and exponential backoff on 429s.

### Quick cURL example
```bash
curl https://api.openai.com/v1/responses \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4.1",
    "input": [{"role":"user","content":"Give me two bullet points about Responses API."}]
  }'
```

### Notes
- Prefer streaming for chat-like experiences.
- Keep conversations small and prune as needed to control context length.
- Store conversation state server-side when working with sensitive data.